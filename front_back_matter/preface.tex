%*******************************************************
% Preface
%*******************************************************
\phantomsection
\markboth{\spacedlowsmallcaps{Preface}}{\spacedlowsmallcaps{Preface}}
\pdfbookmark[1]{Preface}{Preface}
\addcontentsline{toc}{chapter}{\tocEntry{Preface}}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Preface}

\section*{The renascence of statistical sampling}
Nicholas Metropolis defined in this way \cite{metropolis:1987} the period that began in 1945, after the building of ENIAC, the first general purpose electronic computer.
Its first usage was in relation to the problem of the nuclear chain reaction.
The success obtained brought a renascence of a mathematical technique known as statistical sampling, and its usage spread with a new name: the Monte Carlo method.
This name was used in scientific literature for the first time in 1949 by Metropolis and Ulam \cite{metropolis-ulam:1949}.

The main idea of the Monte Carlo method is based on pseudorandom numbers, which are sequences of integer numbers whose properties approximate the properties of random numbers sequences.
From pseudorandom numbers, it is possible to sample sequences of real numbers that are distributed according to a given probability density function.
The applications of this principle are very broad: from numerical approximations of integrals and differential equations, to simulation of events that have a probabilistic nature.

The impact on Physics was enormous. Theoretical physicists not only have a powerful method to compute the predictions of a theory, but is also possible to choose, from a wide-ranging class of theories, the one that is most compatible with experiments.
The Monte Carlo method is also an essential tool for experimental physicists, who can simulate an experimental setup in order to estimate its performance, or to compare the results with the actual experimental results to find if there are problems with the apparatus, or maybe, to discover weakness in physics theories and start working to expand them.

\section*{From local algorithms to cluster algorithms}
A class of problems in which the Monte Carlo method shines is the integral in a very high number of dimensions.
Other methods, like the quadrature rules, suffer the so called \emph{curse of dimensionality}: the error of the approximation in terms of the number of function evaluations scales exponentially with the number of dimensions.
For Monte Carlo, on the other hand, the scaling is independent from the number of dimensions.

A branch of Physics in which such integrals are very frequent is Statistical Mechanics.
In order to compute mean values of observables at thermodynamic equilibrium,
it is necessary to integrate the observable in all configuration in the phase space, weighted in accordance with the Boltzmann distribution.
If it is possible to sample the configurations from the Boltzmann distribution,
the arithmetic mean of the observable evaluated in all these configurations will converge to the correct result of the integral.

A very important step forward in this topic was achieved when Metropolis et al. introduced in 1953 \cite{metropolis:1953} the Metropolis algorithm,
which was further generalized by Hastings in 1970 \cite{hastings:1970} and it is usually referred as Metropolis-Hastings algorithm.
It allows to generate Markov chains of configurations in the phase space that follow a given probability density function.
Its generality and simplicity potentially allow to compute almost any integral that appears in Statistical Mechanics with an improved convergence rate.

An important challenge in Markov chain sampling is achieving ergodicity,
\ie the property according to which the sequence will eventually reach every point in the phase space in a finite number of steps.
Without ergodicity, the Markov chain is actually sampling only a subset of the domain, thus, the integral result will probably be incorrect.
Even if the algorithm is ergodic, if the number of steps needed to reach all relevant sectors of the phase space is too high
with respect to the number of iterations the computer can perform in the available amount of time, the algorithm will effectively behave as it is not ergodic.

An example of this problem is the two dimensional Ising model near the critical temperature.
This system comprises a lattice of spins which can be oriented in two directions.
Each pair of adjacent spins gives a contribute to the total energy: if they are aligned, the contribute is negative, otherwise it is positive.
At thermodynamic equilibrium, if the temperature is above the critical temperature and in absence of external magnetic fields, the mean magnetization of the system is zero.
Below the critical temperature, most of the spins are aligned in the same direction, producing a non-zero mean magnetization.
Varying the temperature in a range of values that are still greater than the critical temperature, but very close to it,
it is possible to observe a critical behaviour: distinct cluster of spins aligned internally all together start arising.
The size of these clusters keeps increasing as the temperature approaches the critical value.

In terms of a Monte Carlo simulation, this cluster structure has important implications.
The energy of the system has a local nature,
\ie it is expressed in terms of the single spins, and, modifying the value of a spin,
the variation of the total energy is only due to the local energy variation.
Because of this fact, the most straightforward way to sample all the configurations is to update all the spins one by one,
changing only one spin at each iteration of the program. This is what is called a local Monte Carlo.
However, when the system is divided into clusters, local algorithms show their weakness.
Updating the spins one per time makes very unlikely that a whole cluster can be reversed,
and this problem gets worse when the cluster size increases.
This is the \emph{critical slowing down}: the correlation length between the configurations increases exponentialy approaching the critical temperature.

A solution to the slowing down for the Ising model\footnote{It applies also to the more general Potts model} was found by Swendsen and Wang in 1987 \cite{swendsen-wang:1987}.
They found a way to sample the Boltzman distribution inverting many contiguous and parallel spins all together.
It is recorded as the first cluster algorithm.
In 1989, Wolff \cite{wolff:1989} improved this algorithm and extended it also to continuous spin models.

Cluster algorithms have a chance to update big groups of elements, and, if they are well defined,
the size of these groups is scalable together with the typical size of the clusters present in the system.
\emph{Critical slowing down} can then be heavily dampened, making the simulations affordable even in critical conditions.

However, the difficulty in creating cluster algorithms is to find a way to efficiently update big parts of the system without compromising the Boltzmann distribution.
This has to be done exploiting properties of the considered system, and, consequently, the algorithm is specifically tailored for systems that share those properties.
For example, Wolff algorithm can be extended to the most generic continuous spin system on a lattice,
but any good solution was not found to extend it to the hard sphere model,
\ie a system in which solid spheres can move in space without overlapping.
The first efficient cluster algorithm for this model was found 1995 by Dress and Krauth \cite{dress-krauth:1995}.
It is called \emph{the pivot algorithm} and was formulated specifically for hard spheres and related systems\footnote{Like binary mixtures or dimers, for example},
independently from the efforts that have been made to extend Wolff algorithm.

Another important case of \emph{critical slowing down} is \emph{topological freezing}.
It affects Quantum Cromodynamics\footnote{As well as other quantum theories with a non-trivial topological structure}
when is studied with the Monte Carlo method in its lattice formulation, \ie Lattice QCD.

\section*{Lattice QCD and topological freezing}
Quantum Cromodynamics is the quantum field theory that describes the \emph{strong interation},
which concerns the coupling between \emph{quarks} (the constituents of nucleons and mesons) and \emph{gluons} (massless particles, mediators of the interaction).
It is formulated as a non-abelian gauge theory, with gauge group SU(3),
in which quark fields lie in the foundamental representation of the group and gluon fields are the gauge fields.
The conserved charge associated with the gauge group is called \emph{color charge} and is the analogous of the \emph{electric charge} in electrodynamics.

This formulation for the theory of strong interation was introduced in 1973 by Fritzsch, Leutwyler and Gell-Mann \cite{fritzsch:1973},
and it is based on the general field theory developed by Yang and Mills in 1954 \cite{yang-mills:1954}.
It came after years of important theoretical contributions that followed the experimental discovery of a growing number of hadrons in 1950s.

In 1973, Gross, Wilczek \cite{gross-wilczek:1973} and Politzer \cite{politzer:1973} discovered an important property of QCD: \emph{asymptotic freedom}.
As the energy scale increases, the strenght of the interaction decreases,
and physical predictions of the theory can be analytically computed with a perturbative power expansion of the coupling constant.

On the other side of the spectrum, when the energy scale decreases, \emph{quark confinement} arises.
As coupling increases, perturbation theory is not viable, and non-perturbative methods are needed to compute theory predictions.
Lattice QCD is a different approach which fulfils these requirements, and it was formulated in 1974 by Wilson \cite{wilson:1974}.
Gauge field theories can be quantized on a finite discrete lattice in euclidean space-time and,
in this fashion, the theory is equivalent to a finite dimensional system at thermodynamic equilibrium.
Continuum limit can then be extrapolated performing Monte Carlo simulations on finer and finer lattices.
















\endgroup

\vfill
